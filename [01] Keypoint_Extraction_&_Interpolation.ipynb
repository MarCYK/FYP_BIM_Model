{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Extract Keypoints from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Color conversion from BGR to RGB\n",
    "    image.flags.writeable = False                   # Image is no longer writeable\n",
    "    results = model.process(image)                  # Make prediction\n",
    "    image.flags.writeable = True                    # Image is no longer writeable\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)   # Color conversion RGB to BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)  # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)    # Draw right connections\n",
    "\n",
    "def draw_styled_landmarks(image,results):\n",
    "    # Draw pose connection\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,255), thickness=5,circle_radius=5),\n",
    "                              mp_drawing.DrawingSpec(color=(80,110,10), thickness=5,circle_radius=5)\n",
    "                              )\n",
    "    # Draw left hand connection\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=5,circle_radius=5),\n",
    "                              mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=5,circle_radius=5)\n",
    "                              )\n",
    "    # Draw right hand connection\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=5,circle_radius=5),\n",
    "                              mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=5,circle_radius=5)\n",
    "                              )\n",
    "    \n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = r'Error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Gestures:  1\n",
      "['abang']\n"
     ]
    }
   ],
   "source": [
    "# Get all file names in the directory\n",
    "gestures_files = os.listdir(video_directory)\n",
    "\n",
    "gesture_folder = np.array(gestures_files)\n",
    "print('Total Gestures: ', len(gesture_folder))\n",
    "print(gesture_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abang : 1\n",
      "Total Videos:  1\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "\n",
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "\n",
    "    sum += len(gesture)\n",
    "\n",
    "    print(gestures, end =\" : \")        \n",
    "    print(len(gesture))\n",
    "\n",
    "print('Total Videos: ', sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Time:  0.3 minutes\n"
     ]
    }
   ],
   "source": [
    "# Estimated Time\n",
    "time = sum * 18 / 60\n",
    "print('Estimated Time: ', time, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\\abang\\01\\landmarks created\n"
     ]
    }
   ],
   "source": [
    "# Create landmark folder\n",
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "            \n",
    "    for ges in gesture:\n",
    "        file = os.path.splitext(ges)\n",
    "        pre_path = os.path.join(video_directory, gestures, file[0])\n",
    "        landmark_path = os.path.join(video_directory, gestures, file[0], 'landmarks')\n",
    "        npy_path = os.path.join(landmark_path, )\n",
    "                    \n",
    "        if not os.path.exists(landmark_path):\n",
    "            os.makedirs(landmark_path)\n",
    "            print(landmark_path + \" created\")\n",
    "        else:\n",
    "            print(landmark_path + \" already exists\")\n",
    "            # # if exist, delete folder and recreate the folder\n",
    "            # shutil.rmtree(pre_path, ignore_errors=True)\n",
    "            # os.makedirs(landmark_path)\n",
    "            # print(\"Exisiting \" + landmark_path + \" deleted and recreated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Error\\\\abang\\\\01']\n"
     ]
    }
   ],
   "source": [
    "# Create save location array\n",
    "save_location_arr = []\n",
    "\n",
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "            \n",
    "    for ges in gesture:\n",
    "        file = os.path.splitext(ges)\n",
    "        save_location_arr.append(os.path.join(video_directory, gestures, file[0]))\n",
    "\n",
    "print(save_location_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Error\\\\abang\\\\01.mp4']\n"
     ]
    }
   ],
   "source": [
    "# Video Path array\n",
    "video_path_arr = []\n",
    "\n",
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "            \n",
    "    for ges in gesture:\n",
    "        file = os.path.splitext(ges)\n",
    "        video_path_arr.append(os.path.join(video_directory, gestures, file[0] + '.mp4'))\n",
    "\n",
    "print(video_path_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false\n",
    "# iterate through the video path array and save the landmarks as images and npy files\n",
    "for video_path, save_location in zip(video_path_arr, save_location_arr):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Edit condifidence and model complexity\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.1, min_tracking_confidence=0.1, model_complexity=2, smooth_landmarks=True) as holistic:\n",
    "            frame, results = mediapipe_detection(frame, holistic)\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            draw_styled_landmarks(frame, results)\n",
    "\n",
    "        ''' Disabled to save time '''\n",
    "        # # create the dark image\n",
    "        # black = np.zeros(frame.shape , np.uint8)\n",
    "\n",
    "        # # Replace the `img` with `black` while drawing the landmarks\n",
    "        # draw_styled_landmarks(black, results)\n",
    "\n",
    "        # frame_save_path = f'{save_location}/{frame_count}.png'\n",
    "        # cv2.imwrite(frame_save_path, black)\n",
    "\n",
    "        # Save the landmarks as npy file\n",
    "        npy_save_path = f'{save_location}/landmarks/{frame_count}.npy'\n",
    "        np.save(npy_save_path, extract_keypoints(results))\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If frame_count > 30, print video path\n",
    "    if frame_count > 30:\n",
    "        extra = frame_count - 30\n",
    "        print(video_path + \" exceeds by \" + str(extra) + \" frames\")\n",
    "    if frame_count < 30:\n",
    "        extra = frame_count - 30\n",
    "        print(video_path + \" not enough \" + str(extra) + \" frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Missing Keypoints Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_hand_keypoints(frames_keypoints):\n",
    "    \"\"\"\n",
    "    Initialize and the hand keypoints in a sequence of frames.\n",
    "\n",
    "    Parameters:\n",
    "    frames_keypoints (list of np.ndarray): List where each entry is a numpy array representing keypoints \n",
    "                                           for a frame, or None if keypoints are missing in that frame.\n",
    "                                           \n",
    "    Returns:\n",
    "    list of np.ndarray: List with hand keypoints initialized and interpolated as needed.\n",
    "    \"\"\"\n",
    "    # Define indices for left and right hand keypoints within the overall keypoint array\n",
    "    pose_keypoints_count = 33 * 4\n",
    "    left_hand_start = pose_keypoints_count\n",
    "    left_hand_end = left_hand_start + 21 * 3\n",
    "    right_hand_start = left_hand_end\n",
    "    right_hand_end = right_hand_start + 21 * 3\n",
    "\n",
    "    '''\n",
    "    array[1, 1, 1, 1, 0, 0 ,0 ,1 ,1 ,1]\n",
    "    '''\n",
    "    \n",
    "    # Extract valid hand keypoints for averaging\n",
    "    valid_left_hand_keypoints = [kp[left_hand_start:left_hand_end] for kp in frames_keypoints if kp is not None and (kp[left_hand_start] != 0.00000000e+00)]\n",
    "    valid_right_hand_keypoints = [kp[right_hand_start:right_hand_end] for kp in frames_keypoints if kp is not None and (kp[right_hand_start] != 0.00000000e+00)]\n",
    "    \n",
    "    print(\"valid_left_hand\", len(valid_left_hand_keypoints))\n",
    "    print(\"valid_right_hand\", len(valid_right_hand_keypoints))\n",
    "\n",
    "    # Calculate average hand keypoints\n",
    "    if valid_left_hand_keypoints:\n",
    "        avg_left_hand = np.mean(valid_left_hand_keypoints, axis=0)\n",
    "    else:\n",
    "        avg_left_hand = np.zeros(21 * 3)\n",
    "    \n",
    "    if valid_right_hand_keypoints:\n",
    "        avg_right_hand = np.mean(valid_right_hand_keypoints, axis=0)\n",
    "    else:\n",
    "        avg_right_hand = np.zeros(21 * 3)\n",
    "\n",
    "    # Initialize the first and last frames if they have missing hand keypoints\n",
    "    if frames_keypoints[0] is None or not np.any(frames_keypoints[0][left_hand_start:left_hand_end]):\n",
    "        frames_keypoints[0][left_hand_start:left_hand_end] = avg_left_hand\n",
    "    if frames_keypoints[0] is None or not np.any(frames_keypoints[0][right_hand_start:right_hand_end]):\n",
    "        frames_keypoints[0][right_hand_start:right_hand_end] = avg_right_hand\n",
    "    \n",
    "    if frames_keypoints[-1] is None or not np.any(frames_keypoints[-1][left_hand_start:left_hand_end]):\n",
    "        frames_keypoints[-1][left_hand_start:left_hand_end] = avg_left_hand\n",
    "    if frames_keypoints[-1] is None or not np.any(frames_keypoints[-1][right_hand_start:right_hand_end]):\n",
    "        frames_keypoints[-1][right_hand_start:right_hand_end] = avg_right_hand\n",
    "\n",
    "    return frames_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbour_keypoints(frames_keypoints, k, frame, hand_start, hand_end):\n",
    "    alpha_left = alpha_right = beta_left = beta_right = None\n",
    "\n",
    "    # Search for α (previous frame with keypoints)\n",
    "    for a in range(1, k + 1):\n",
    "        if frames_keypoints[k - a] is not None and np.any(frames_keypoints[k - a][hand_start:hand_end]):\n",
    "            alpha_left = a\n",
    "            break\n",
    "\n",
    "    # Search for β (next frame with keypoints)\n",
    "    for b in range(1, len(frames_keypoints) - k):\n",
    "        if frames_keypoints[k + b] is not None and np.any(frames_keypoints[k + b][hand_start:hand_end]):\n",
    "            beta_left = b\n",
    "            break\n",
    "\n",
    "    # If α and β are found, interpolate\n",
    "    if alpha_left is not None and beta_left is not None:\n",
    "        f_k_alpha_left = frames_keypoints[k - alpha_left][hand_start:hand_end]\n",
    "        f_k_beta_left = frames_keypoints[k + beta_left][hand_start:hand_end]\n",
    "        frame[hand_start:hand_end] = (beta_left * f_k_alpha_left + alpha_left * f_k_beta_left) / (alpha_left + beta_left)\n",
    "\n",
    "def bilinear_interpolation(frames_keypoints):\n",
    "    \"\"\"\n",
    "    Apply bilinear interpolation to fill missing hand keypoints based on the provided formula.\n",
    "    \n",
    "    Parameters:\n",
    "    frames_keypoints (list of np.ndarray): List where each entry is a numpy array representing keypoints \n",
    "                                           for a frame, or None if keypoints are missing in that frame.\n",
    "                                           \n",
    "    Returns:\n",
    "    list of np.ndarray: List of frames with interpolated hand keypoints.\n",
    "    \"\"\"\n",
    "    # Define indices for left and right hand keypoints within the overall keypoint array\n",
    "    pose_keypoints_count = 33 * 4\n",
    "    left_hand_start = pose_keypoints_count\n",
    "    left_hand_end = left_hand_start + 21 * 3\n",
    "    right_hand_start = left_hand_end\n",
    "    right_hand_end = right_hand_start + 21 * 3\n",
    "\n",
    "    # Process each frame\n",
    "    for k in range(len(frames_keypoints)):\n",
    "        frame = frames_keypoints[k]\n",
    "        \n",
    "        # Check if current frame's hand keypoints are missing\n",
    "        if frame is None or (frame[left_hand_start] == 0.00000000e+00 or frame[right_hand_start] == 0.00000000e+00):\n",
    "            # Find α and β for left and right hands\n",
    "            # Initialize α and β to None as we search\n",
    "\n",
    "            if frame[left_hand_start] == 0.00000000e+00:\n",
    "                find_neighbour_keypoints(frames_keypoints, k, frame, left_hand_start, left_hand_end)\n",
    "                print('frame ', k + 1, ' left hand keypoints interpolated')\n",
    "\n",
    "            if frame[right_hand_start] == 0.00000000e+00:\n",
    "                find_neighbour_keypoints(frames_keypoints, k, frame, right_hand_start, right_hand_end)\n",
    "                print('frame ', k + 1, ' right hand keypoints interpolated')\n",
    "\n",
    "    return frames_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints(folder_path):\n",
    "    \"\"\"\n",
    "    Load the keypoints from a given file path.\n",
    "    \n",
    "    Parameters:\n",
    "    path (str): Path to the .npy file containing the keypoints.\n",
    "    \n",
    "    Returns:\n",
    "    list of np.ndarray: List of frames where each frame is a numpy array representing keypoints.\n",
    "    \"\"\"\n",
    "    frames_keypoints = []\n",
    "\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
    "    # print(files)\n",
    "\n",
    "    # arrange files in ascending order\n",
    "    files.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "    print(files)\n",
    "\n",
    "    # Load the keypoints from the .npy file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        frame_keypoints = np.load(file_path)\n",
    "        frames_keypoints.append(frame_keypoints)\n",
    "\n",
    "    return frames_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keypoints(frames_keypoints, folder_path):\n",
    "    \"\"\"\n",
    "    Save the keypoints to a given file path.\n",
    "    \n",
    "    Parameters:\n",
    "    frames_keypoints (list of np.ndarray): List of frames where each frame is a numpy array representing keypoints.\n",
    "    folder_path (str): Path to the folder where the keypoints will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    else:\n",
    "        # if exist, delete folder and recreate the folder\n",
    "        shutil.rmtree(folder_path, ignore_errors=True)\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    for i, frame_keypoints in enumerate(frames_keypoints):\n",
    "        file_path = os.path.join(folder_path, f'{i + 1}.npy')\n",
    "        np.save(file_path, frame_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_directory = r'DATASET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Gestures:  1\n",
      "['abang']\n"
     ]
    }
   ],
   "source": [
    "# Get all file names in the directory\n",
    "gestures_files = os.listdir(video_directory)\n",
    "\n",
    "gesture_folder = np.array(gestures_files)\n",
    "print('Total Gestures: ', len(gesture_folder))\n",
    "print(gesture_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abang : ['01']\n"
     ]
    }
   ],
   "source": [
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "\n",
    "    print(gestures, end =\" : \")        \n",
    "    print(gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\\abang\\01\\interpolated_landmarks already exists\n"
     ]
    }
   ],
   "source": [
    "# Create landmark folder\n",
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "            \n",
    "    for ges in gesture:\n",
    "        file = os.path.splitext(ges)\n",
    "        pre_path = os.path.join(video_directory, gestures, file[0])\n",
    "        interpolated_path = os.path.join(video_directory, gestures, file[0], 'interpolated_landmarks')\n",
    "        npy_path = os.path.join(interpolated_path, )\n",
    "                    \n",
    "        if not os.path.exists(interpolated_path):\n",
    "            os.makedirs(interpolated_path)\n",
    "            print(interpolated_path + \" created\")\n",
    "        else:\n",
    "            print(interpolated_path + \" already exists\")\n",
    "            # # if exist, delete folder and recreate the folder\n",
    "            # shutil.rmtree(pre_path, ignore_errors=True)\n",
    "            # os.makedirs(interpolated_path)\n",
    "            # print(\"Exisiting \" + interpolated_path + \" deleted and recreated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bilinear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.npy', '2.npy', '3.npy', '4.npy', '5.npy', '6.npy', '7.npy', '8.npy', '9.npy', '10.npy', '11.npy', '12.npy', '13.npy', '14.npy', '15.npy', '16.npy', '17.npy', '18.npy', '19.npy', '20.npy', '21.npy', '22.npy', '23.npy', '24.npy', '25.npy', '26.npy', '27.npy', '28.npy', '29.npy', '30.npy']\n",
      "valid_left_hand 20\n",
      "valid_right_hand 0\n",
      "frame  1  right hand keypoints interpolated\n",
      "frame  2  right hand keypoints interpolated\n",
      "frame  3  right hand keypoints interpolated\n",
      "frame  4  right hand keypoints interpolated\n",
      "frame  5  right hand keypoints interpolated\n",
      "frame  6  right hand keypoints interpolated\n",
      "frame  7  right hand keypoints interpolated\n",
      "frame  8  right hand keypoints interpolated\n",
      "frame  9  right hand keypoints interpolated\n",
      "frame  10  right hand keypoints interpolated\n",
      "frame  11  right hand keypoints interpolated\n",
      "frame  12  right hand keypoints interpolated\n",
      "frame  13  right hand keypoints interpolated\n",
      "frame  14  right hand keypoints interpolated\n",
      "frame  15  right hand keypoints interpolated\n",
      "frame  16  right hand keypoints interpolated\n",
      "frame  17  right hand keypoints interpolated\n",
      "frame  18  right hand keypoints interpolated\n",
      "frame  19  right hand keypoints interpolated\n",
      "frame  20  right hand keypoints interpolated\n",
      "frame  21  left hand keypoints interpolated\n",
      "frame  21  right hand keypoints interpolated\n",
      "frame  22  left hand keypoints interpolated\n",
      "frame  22  right hand keypoints interpolated\n",
      "frame  23  left hand keypoints interpolated\n",
      "frame  23  right hand keypoints interpolated\n",
      "frame  24  left hand keypoints interpolated\n",
      "frame  24  right hand keypoints interpolated\n",
      "frame  25  left hand keypoints interpolated\n",
      "frame  25  right hand keypoints interpolated\n",
      "frame  26  left hand keypoints interpolated\n",
      "frame  26  right hand keypoints interpolated\n",
      "frame  27  left hand keypoints interpolated\n",
      "frame  27  right hand keypoints interpolated\n",
      "frame  28  left hand keypoints interpolated\n",
      "frame  28  right hand keypoints interpolated\n",
      "frame  29  left hand keypoints interpolated\n",
      "frame  29  right hand keypoints interpolated\n",
      "frame  30  right hand keypoints interpolated\n"
     ]
    }
   ],
   "source": [
    "# %%script false\n",
    "# Perform interpolation on the landmarks\n",
    "for gestures in gesture_folder:\n",
    "    gesture = []\n",
    "\n",
    "    for fname in os.listdir(os.path.join(video_directory, gestures)):\n",
    "        path = os.path.join(video_directory, gestures, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue\n",
    "        else:\n",
    "            ges = os.path.splitext(fname)[0]\n",
    "            gesture.append(ges)\n",
    "            \n",
    "    for ges in gesture:\n",
    "        file = os.path.splitext(ges)\n",
    "        load_path = os.path.join(video_directory, gestures, file[0], 'landmarks')\n",
    "        save_path = os.path.join(video_directory, gestures, file[0], 'interpolated_landmarks')\n",
    "        frames_keypoints = load_keypoints(load_path)\n",
    "        frames_keypoints = initialize_hand_keypoints(frames_keypoints)\n",
    "        frames_keypoints = bilinear_interpolation(frames_keypoints)\n",
    "        save_keypoints(frames_keypoints, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = r'Error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keypoints(keypoints, title):\n",
    "    # Separate pose, left hand, and right hand keypoints based on sizes\n",
    "    pose = keypoints[:33 * 4].reshape(-1, 4)        # 33 keypoints, each with [x, y, z, visibility]\n",
    "    left_hand = keypoints[33 * 4:33 * 4 + 21 * 3].reshape(-1, 3)  # 21 keypoints for left hand, each with [x, y, z]\n",
    "    right_hand = keypoints[33 * 4 + 21 * 3:].reshape(-1, 3)       # 21 keypoints for right hand, each with [x, y, z]\n",
    "\n",
    "    # Define connections (edges) between keypoints for pose, left hand, and right hand\n",
    "    # These connections are based on a standard pose model, such as MediaPipe's Pose model.\n",
    "    pose_connections = [\n",
    "        (0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8), (9, 10),\n",
    "        (11, 12), (11, 13), (13, 15), (15, 17), (15, 19), (15, 21), (17, 19),\n",
    "        (12, 14), (14, 16), (16, 18), (16, 20), (16, 22), (18, 20), (23, 24),\n",
    "        (23, 25), (24, 26), (25, 27), (26, 28), (27, 29), (28, 30), (29, 31), (30, 32)\n",
    "    ]\n",
    "\n",
    "    hand_connections = [\n",
    "        (0, 1), (1, 2), (2, 3), (3, 4), # Thumb\n",
    "        (0, 5), (5, 6), (6, 7), (7, 8), # Index finger\n",
    "        (0, 9), (9, 10), (10, 11), (11, 12), # Middle finger\n",
    "        (0, 13), (13, 14), (14, 15), (15, 16), # Ring finger\n",
    "        (0, 17), (17, 18), (18, 19), (19, 20) # Pinky\n",
    "    ]\n",
    "\n",
    "    # Plot keypoints with connections\n",
    "    plt.figure(figsize=(4.8, 2.7))\n",
    "    plt.axis([0, 1.125, 0, 2])\n",
    "\n",
    "    # Plot pose keypoints and connections\n",
    "    for (start, end) in pose_connections:\n",
    "        plt.plot([pose[start, 0], pose[end, 0]], [pose[start, 1], pose[end, 1]], 'k-', lw=2)\n",
    "    plt.scatter(pose[:, 0], pose[:, 1], label='Pose', s=20, alpha=0.7)\n",
    "\n",
    "    # Plot left hand keypoints and connections\n",
    "    for (start, end) in hand_connections:\n",
    "        plt.plot([left_hand[start, 0], left_hand[end, 0]], [left_hand[start, 1], left_hand[end, 1]], 'b-', lw=2)\n",
    "    plt.scatter(left_hand[:, 0], left_hand[:, 1], label='Left Hand', s=20, alpha=0.7)\n",
    "\n",
    "    # Plot right hand keypoints and connections\n",
    "    for (start, end) in hand_connections:\n",
    "        plt.plot([right_hand[start, 0], right_hand[end, 0]], [right_hand[start, 1], right_hand[end, 1]], 'r-', lw=2)\n",
    "    plt.scatter(right_hand[:, 0], right_hand[:, 1], label='Right Hand', s=20, alpha=0.7)\n",
    "\n",
    "    # Adjust plot settings\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    # Adjust plot settings\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    leg = ax.get_legend()\n",
    "    leg.legend_handles[0].set_color('black')\n",
    "    leg.legend_handles[1].set_color('blue')\n",
    "    leg.legend_handles[2].set_color('red')\n",
    "    plt.axis('off')\n",
    "    plt.gca().invert_yaxis()  # Invert Y axis for typical image coordinates\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interpolation(gesture, video_num, frame_num):\n",
    "    \"\"\"\n",
    "    Visualize the original and interpolated keypoints for a specific frame in a video.\n",
    "    \n",
    "    Parameters:\n",
    "    gesture (str): Name of the gesture.\n",
    "    video_num (int): Number of the video.\n",
    "    frame_num (int): Number of the frame to visualize.\n",
    "    \"\"\"\n",
    "    # Load original and interpolated keypoints\n",
    "    npy_file = f'{frame_num}.npy'\n",
    "    keypoints = np.load(os.path.join(video_directory, gesture, f'{video_num:02}', 'landmarks', npy_file))\n",
    "    keypoints_interpolated = np.load(os.path.join(video_directory, gesture, f'{video_num:02}', 'interpolated_landmarks', npy_file))\n",
    "    # keypoints_flipped = np.load(os.path.join(video_directory, gesture, f'{video_num:02}', 'flipped', npy_file))\n",
    "\n",
    "    # Plot original and interpolated keypoints\n",
    "    plot_keypoints(keypoints, title='Original Keypoints')\n",
    "    plot_keypoints(keypoints_interpolated, title='Interpolated Keypoints')\n",
    "    # plot_keypoints(keypoints_flipped, title='Flipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "visualize_interpolation('berapa', 28, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hujan\n",
    "| Original | Interpolated |\n",
    "| ------------- | ------------- |\n",
    "| ![display image](gif/hujan/landmarks.gif) | ![display image](gif/hujan/interpolated_landmarks.gif) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kedai\n",
    "| Original | Interpolated |\n",
    "| ------------- | ------------- |\n",
    "| ![display image](gif/kedai/landmarks.gif) | ![display image](gif/kedai/interpolated_landmarks.gif) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada\n",
    "| Original | Interpolated |\n",
    "| ------------- | ------------- |\n",
    "| ![display image](gif/ada/landmarks.gif) | ![display image](gif/ada/interpolated_landmarks.gif) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saudara\n",
    "| Original | Interpolated |\n",
    "| ------------- | ------------- |\n",
    "| ![display image](gif/saudara/landmarks.gif) | ![display image](gif/saudara/interpolated_landmarks.gif) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIM_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
